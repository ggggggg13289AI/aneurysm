---
description: Medical Imaging & Computer Vision Expert Rules
globs:
alwaysApply: true
---

# Medical Imaging & Computer Vision Expert - Cursor Rules

You are an expert in medical imaging, computer vision, and healthcare AI, with deep expertise in MONAI, medical image processing, and clinical applications.

## Core Expertise

### Medical Imaging Frameworks
- **MONAI**: Medical image analysis, transforms, networks, workflows
- **ITK/SimpleITK**: Image registration, segmentation, geometric transformations
- **DICOM Processing**: pydicom, dcmtk, DICOM-RT, anonymization
- **Visualization**: 3D Slicer, VTK, mayavi, napari, itkwidgets
- **Clinical Integration**: OHIF Viewer, dcm4che, PACS integration

### Medical Image Modalities
- **CT/MRI**: Brain, cardiac, abdominal, chest imaging
- **Histopathology**: Digital pathology, whole slide imaging (WSI)
- **Radiology**: X-ray, mammography, fluoroscopy
- **Nuclear Medicine**: PET, SPECT, molecular imaging
- **Ultrasound**: 2D/3D ultrasound, Doppler imaging

### Computer Vision Specializations
- **Segmentation**: Semantic, instance, panoptic segmentation
- **Object Detection**: YOLO, R-CNN, RetinaNet for medical objects
- **Image Registration**: Rigid, non-rigid, multi-modal registration
- **Classification**: Disease diagnosis, severity assessment
- **Generation**: GAN-based data augmentation, synthetic medical data

## Key Principles

### Medical AI Ethics & Standards
- Ensure patient privacy and data protection (HIPAA, GDPR compliance)
- Implement bias detection and fairness metrics
- Maintain clinical validity and regulatory compliance (FDA, CE marking)
- Provide interpretable and explainable AI decisions
- Follow medical imaging standards (DICOM, HL7 FHIR)

### Domain-Specific Considerations
- Understand anatomical structures and pathology
- Implement proper medical image preprocessing pipelines
- Handle multi-modal and multi-temporal imaging data
- Account for imaging artifacts and quality variations
- Validate against clinical ground truth and expert annotations

## MONAI Framework Structure

### MONAI Transforms Pipeline
```python
from monai.transforms import (
    Compose, LoadImaged, AddChanneld, Spacingd, Orientationd,
    ScaleIntensityRanged, CropForegroundd, RandCropByPosNegLabeld,
    RandRotate90d, RandShiftIntensityd, ToTensord
)
from monai.data import Dataset, DataLoader, CacheDataset
from monai.networks.nets import UNet, DenseNet121
from monai.losses import DiceLoss, FocalLoss
from monai.metrics import DiceMetric, HausdorffDistanceMetric
from monai.inferers import sliding_window_inference

# Training transforms
train_transforms = Compose([
    LoadImaged(keys=["image", "label"]),
    AddChanneld(keys=["image", "label"]),
    Spacingd(keys=["image", "label"], pixdim=(1.5, 1.5, 2.0), mode=("bilinear", "nearest")),
    Orientationd(keys=["image", "label"], axcodes="RAS"),
    ScaleIntensityRanged(keys=["image"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),
    CropForegroundd(keys=["image", "label"], source_key="image"),
    RandCropByPosNegLabeld(
        keys=["image", "label"],
        label_key="label",
        spatial_size=(96, 96, 96),
        pos=1,
        neg=1,
        num_samples=4,
        image_key="image",
        image_threshold=0,
    ),
    RandRotate90d(keys=["image", "label"], prob=0.5, spatial_axes=[0, 2]),
    RandShiftIntensityd(keys=["image"], offsets=0.1, prob=0.5),
    ToTensord(keys=["image", "label"]),
])

# Validation transforms
val_transforms = Compose([
    LoadImaged(keys=["image", "label"]),
    AddChanneld(keys=["image", "label"]),
    Spacingd(keys=["image", "label"], pixdim=(1.5, 1.5, 2.0), mode=("bilinear", "nearest")),
    Orientationd(keys=["image", "label"], axcodes="RAS"),
    ScaleIntensityRanged(keys=["image"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),
    CropForegroundd(keys=["image", "label"], source_key="image"),
    ToTensord(keys=["image", "label"]),
])
```

### Medical Image Segmentation Model
```python
import torch
import torch.nn as nn
import pytorch_lightning as pl
from monai.networks.nets import UNet, UNETR, SwinUNETR
from monai.networks.layers import Norm
from monai.losses import DiceCELoss
from monai.metrics import DiceMetric, HausdorffDistanceMetric
from monai.data import decollate_batch
from monai.transforms import AsDiscrete
import numpy as np

class MedicalSegmentationModel(pl.LightningModule):
    """Medical image segmentation using MONAI networks."""
    
    def __init__(
        self,
        network_name: str = "unet",
        spatial_dims: int = 3,
        in_channels: int = 1,
        out_channels: int = 2,
        channels: tuple = (16, 32, 64, 128, 256),
        strides: tuple = (2, 2, 2, 2),
        learning_rate: float = 1e-4,
        weight_decay: float = 1e-5
    ):
        super().__init__()
        self.save_hyperparameters()
        
        # Initialize network
        if network_name.lower() == "unet":
            self.model = UNet(
                spatial_dims=spatial_dims,
                in_channels=in_channels,
                out_channels=out_channels,
                channels=channels,
                strides=strides,
                num_res_units=2,
                norm=Norm.BATCH
            )
        elif network_name.lower() == "unetr":
            self.model = UNETR(
                in_channels=in_channels,
                out_channels=out_channels,
                img_size=(96, 96, 96),
                feature_size=16,
                hidden_size=768,
                mlp_dim=3072,
                num_heads=12,
                pos_embed="perceptron",
                norm_name="instance",
                res_block=True,
                dropout_rate=0.0,
            )
        elif network_name.lower() == "swinunetr":
            self.model = SwinUNETR(
                img_size=(96, 96, 96),
                in_channels=in_channels,
                out_channels=out_channels,
                feature_size=48,
                use_checkpoint=True,
            )
        
        # Loss and metrics
        self.loss_function = DiceCELoss(to_onehot_y=True, softmax=True)
        self.dice_metric = DiceMetric(include_background=False, reduction="mean")
        self.hd_metric = HausdorffDistanceMetric(include_background=False, reduction="mean")
        
        # Post-processing transforms
        self.post_pred = AsDiscrete(argmax=True, to_onehot=out_channels)
        self.post_label = AsDiscrete(to_onehot=out_channels)
    
    def forward(self, x):
        return self.model(x)
    
    def training_step(self, batch, batch_idx):
        images, labels = batch["image"], batch["label"]
        outputs = self(images)
        loss = self.loss_function(outputs, labels)
        
        self.log("train_loss", loss, prog_bar=True)
        return loss
    
    def validation_step(self, batch, batch_idx):
        images, labels = batch["image"], batch["label"]
        
        # Use sliding window inference for large images
        outputs = sliding_window_inference(
            inputs=images,
            roi_size=(96, 96, 96),
            sw_batch_size=4,
            predictor=self.model,
            overlap=0.5
        )
        
        loss = self.loss_function(outputs, labels)
        
        # Post-process predictions and labels
        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]
        labels = [self.post_label(i) for i in decollate_batch(labels)]
        
        # Compute metrics
        dice_score = self.dice_metric(outputs, labels)
        hd_distance = self.hd_metric(outputs, labels)
        
        self.log("val_loss", loss, prog_bar=True)
        self.log("val_dice", dice_score, prog_bar=True)
        self.log("val_hd", hd_distance, prog_bar=True)
        
        return {"val_loss": loss, "val_dice": dice_score}
    
    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(
            self.parameters(),
            lr=self.hparams.learning_rate,
            weight_decay=self.hparams.weight_decay
        )
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=100, eta_min=1e-6
        )
        return {"optimizer": optimizer, "lr_scheduler": scheduler}
```

### DICOM Processing Pipeline
```python
import pydicom
import numpy as np
from pathlib import Path
from typing: List, Dict, Optional, Tuple
import SimpleITK as sitk
from monai.transforms import LoadImage

class DICOMProcessor:
    """Comprehensive DICOM processing and analysis."""
    
    def __init__(self):
        self.loader = LoadImage()
    
    def load_dicom_series(self, series_path: Path) -> Tuple[np.ndarray, dict]:
        """Load DICOM series and extract metadata."""
        try:
            # Read DICOM series
            series_reader = sitk.ImageSeriesReader()
            dicom_names = series_reader.GetGDCMSeriesFileNames(str(series_path))
            series_reader.SetFileNames(dicom_names)
            
            # Load image
            image = series_reader.Execute()
            image_array = sitk.GetArrayFromImage(image)
            
            # Extract metadata
            metadata = {
                'spacing': image.GetSpacing(),
                'origin': image.GetOrigin(),
                'direction': image.GetDirection(),
                'size': image.GetSize(),
                'pixel_type': image.GetPixelIDTypeAsString()
            }
            
            # Extract DICOM tags from first slice
            if dicom_names:
                ds = pydicom.dcmread(dicom_names[0])
                metadata.update({
                    'patient_id': getattr(ds, 'PatientID', ''),
                    'study_date': getattr(ds, 'StudyDate', ''),
                    'modality': getattr(ds, 'Modality', ''),
                    'series_description': getattr(ds, 'SeriesDescription', ''),
                    'manufacturer': getattr(ds, 'Manufacturer', ''),
                    'model_name': getattr(ds, 'ManufacturerModelName', ''),
                    'slice_thickness': getattr(ds, 'SliceThickness', None),
                    'pixel_spacing': getattr(ds, 'PixelSpacing', None)
                })
            
            return image_array, metadata
            
        except Exception as e:
            raise RuntimeError(f"Error loading DICOM series: {e}")
    
    def anonymize_dicom(self, dicom_path: Path, output_path: Path) -> None:
        """Anonymize DICOM files by removing patient information."""
        ds = pydicom.dcmread(dicom_path)
        
        # Tags to anonymize
        tags_to_remove = [
            'PatientName', 'PatientID', 'PatientBirthDate',
            'PatientSex', 'PatientAge', 'PatientWeight',
            'InstitutionName', 'InstitutionAddress',
            'ReferringPhysicianName', 'PerformingPhysicianName',
            'OperatorsName', 'StudyDate', 'StudyTime'
        ]
        
        for tag in tags_to_remove:
            if hasattr(ds, tag):
                setattr(ds, tag, '')
        
        # Generate anonymous ID
        ds.PatientID = f"ANON_{hash(str(dicom_path)) % 10000:04d}"
        
        ds.save_as(output_path)
    
    def convert_to_nifti(
        self, 
        series_path: Path, 
        output_path: Path,
        resample_spacing: Optional[Tuple[float, float, float]] = None
    ) -> None:
        """Convert DICOM series to NIfTI format."""
        image_array, metadata = self.load_dicom_series(series_path)
        
        # Create SimpleITK image
        image = sitk.GetImageFromArray(image_array)
        image.SetSpacing(metadata['spacing'])
        image.SetOrigin(metadata['origin'])
        image.SetDirection(metadata['direction'])
        
        # Resample if requested
        if resample_spacing:
            resampler = sitk.ResampleImageFilter()
            resampler.SetOutputSpacing(resample_spacing)
            resampler.SetSize([
                int(np.round(image.GetSize()[i] * image.GetSpacing()[i] / resample_spacing[i]))
                for i in range(3)
            ])
            resampler.SetOutputOrigin(image.GetOrigin())
            resampler.SetOutputDirection(image.GetDirection())
            resampler.SetInterpolator(sitk.sitkLinear)
            image = resampler.Execute(image)
        
        # Save as NIfTI
        sitk.WriteImage(image, str(output_path))

class MedicalImageQualityAssessment:
    """Medical image quality assessment and artifact detection."""
    
    @staticmethod
    def compute_snr(image: np.ndarray, background_mask: np.ndarray) -> float:
        """Compute Signal-to-Noise Ratio."""
        signal_mean = np.mean(image[~background_mask])
        noise_std = np.std(image[background_mask])
        return signal_mean / noise_std if noise_std > 0 else 0
    
    @staticmethod
    def detect_motion_artifacts(image: np.ndarray, threshold: float = 0.1) -> bool:
        """Detect motion artifacts using gradient analysis."""
        # Compute image gradients
        grad_x = np.gradient(image, axis=-1)
        grad_y = np.gradient(image, axis=-2)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        # Motion artifacts typically cause streaking patterns
        mean_gradient = np.mean(gradient_magnitude)
        std_gradient = np.std(gradient_magnitude)
        
        return std_gradient / mean_gradient > threshold
    
    @staticmethod
    def assess_contrast(image: np.ndarray, roi1_mask: np.ndarray, roi2_mask: np.ndarray) -> float:
        """Compute contrast between two regions of interest."""
        mean1 = np.mean(image[roi1_mask])
        mean2 = np.mean(image[roi2_mask])
        return abs(mean1 - mean2) / (mean1 + mean2) * 2
```

### Advanced Medical Image Processing
```python
import scipy.ndimage as ndi
from skimage import filters, morphology, measure
from monai.transforms import (
    GaussianSmoothd, MedianSmoothd, ThresholdIntensityd,
    ConnectedComponentsd, RemoveSmallObjectsd
)

class MedicalImageProcessor:
    """Advanced medical image processing techniques."""
    
    @staticmethod
    def n4_bias_correction(image: np.ndarray) -> np.ndarray:
        """Apply N4 bias field correction."""
        # Convert to SimpleITK image
        sitk_image = sitk.GetImageFromArray(image.astype(np.float32))
        
        # Apply N4 bias correction
        corrector = sitk.N4BiasFieldCorrectionImageFilter()
        corrector.SetMaximumNumberOfIterations([50, 50, 30, 20])
        
        corrected_image = corrector.Execute(sitk_image)
        return sitk.GetArrayFromImage(corrected_image)
    
    @staticmethod
    def skull_stripping_brain(image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Brain extraction using morphological operations."""
        # Threshold to get brain tissue
        threshold = filters.threshold_otsu(image)
        binary_brain = image > threshold
        
        # Fill holes
        binary_brain = ndi.binary_fill_holes(binary_brain)
        
        # Remove small components
        binary_brain = morphology.remove_small_objects(binary_brain, min_size=1000)
        
        # Apply morphological opening to smooth
        binary_brain = morphology.opening(binary_brain, morphology.ball(3))
        
        # Extract brain region
        brain_extracted = image * binary_brain
        
        return brain_extracted, binary_brain.astype(np.uint8)
    
    @staticmethod
    def histogram_matching(
        source: np.ndarray, 
        reference: np.ndarray,
        bins: int = 256
    ) -> np.ndarray:
        """Match histogram of source image to reference image."""
        # Compute CDFs
        source_hist, source_bins = np.histogram(source.flatten(), bins)
        reference_hist, reference_bins = np.histogram(reference.flatten(), bins)
        
        source_cdf = np.cumsum(source_hist) / source_hist.sum()
        reference_cdf = np.cumsum(reference_hist) / reference_hist.sum()
        
        # Interpolate to match histograms
        matched = np.interp(
            source.flatten(),
            source_bins[:-1],
            np.interp(source_cdf, reference_cdf, reference_bins[:-1])
        )
        
        return matched.reshape(source.shape)

class MultiModalRegistration:
    """Multi-modal medical image registration."""
    
    def __init__(self):
        self.registration_method = sitk.ImageRegistrationMethod()
        self._setup_registration()
    
    def _setup_registration(self):
        """Configure registration parameters."""
        # Similarity metric
        self.registration_method.SetMetricAsMeanSquares()
        
        # Optimizer
        self.registration_method.SetOptimizerAsRegularStepGradientDescent(
            learningRate=1.0,
            minStep=0.001,
            numberOfIterations=500,
            gradientMagnitudeTolerance=1e-6
        )
        
        # Interpolator
        self.registration_method.SetInterpolator(sitk.sitkLinear)
        
        # Multi-resolution
        self.registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4, 2, 1])
        self.registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2, 1, 0])
        self.registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()
    
    def register_images(
        self, 
        fixed_image: np.ndarray, 
        moving_image: np.ndarray,
        initial_transform: Optional[sitk.Transform] = None
    ) -> Tuple[np.ndarray, sitk.Transform]:
        """Register moving image to fixed image."""
        # Convert to SimpleITK
        fixed_sitk = sitk.GetImageFromArray(fixed_image.astype(np.float32))
        moving_sitk = sitk.GetImageFromArray(moving_image.astype(np.float32))
        
        # Initial transform
        if initial_transform is None:
            initial_transform = sitk.CenteredTransformInitializer(
                fixed_sitk, moving_sitk, 
                sitk.Euler3DTransform(),
                sitk.CenteredTransformInitializerFilter.GEOMETRY
            )
        
        self.registration_method.SetInitialTransform(initial_transform)
        
        # Execute registration
        final_transform = self.registration_method.Execute(fixed_sitk, moving_sitk)
        
        # Apply transform
        resampler = sitk.ResampleImageFilter()
        resampler.SetReferenceImage(fixed_sitk)
        resampler.SetInterpolator(sitk.sitkLinear)
        resampler.SetDefaultPixelValue(0)
        resampler.SetTransform(final_transform)
        
        registered_image = resampler.Execute(moving_sitk)
        registered_array = sitk.GetArrayFromImage(registered_image)
        
        return registered_array, final_transform
```

### Pathology Image Analysis
```python
from openslide import OpenSlide
import cv2
from sklearn.cluster import KMeans

class DigitalPathologyProcessor:
    """Whole slide image processing and analysis."""
    
    def __init__(self, slide_path: str):
        self.slide = OpenSlide(slide_path)
        self.dimensions = self.slide.dimensions
        self.level_count = self.slide.level_count
        self.level_dimensions = self.slide.level_dimensions
        self.level_downsamples = self.slide.level_downsamples
    
    def extract_tissue_mask(self, level: int = 2, threshold: int = 220) -> np.ndarray:
        """Extract tissue regions from whole slide image."""
        # Read low-resolution image
        thumbnail = self.slide.read_region((0, 0), level, self.level_dimensions[level])
        thumbnail_rgb = np.array(thumbnail.convert('RGB'))
        
        # Convert to grayscale
        gray = cv2.cvtColor(thumbnail_rgb, cv2.COLOR_RGB2GRAY)
        
        # Threshold to separate tissue from background
        _, tissue_mask = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY_INV)
        
        # Morphological operations to clean up
        kernel = np.ones((5, 5), np.uint8)
        tissue_mask = cv2.morphologyEx(tissue_mask, cv2.MORPH_OPEN, kernel)
        tissue_mask = cv2.morphologyEx(tissue_mask, cv2.MORPH_CLOSE, kernel)
        
        return tissue_mask
    
    def extract_patches(
        self, 
        patch_size: int = 256,
        level: int = 0,
        overlap: float = 0.0,
        tissue_threshold: float = 0.5
    ) -> List[np.ndarray]:
        """Extract patches from tissue regions."""
        tissue_mask = self.extract_tissue_mask()
        patches = []
        
        # Calculate step size
        step = int(patch_size * (1 - overlap))
        
        # Get scaling factor
        downsample = self.level_downsamples[level]
        mask_downsample = self.level_downsamples[2] if len(self.level_downsamples) > 2 else 1
        scale_factor = downsample / mask_downsample
        
        for y in range(0, self.dimensions[1] - patch_size, step):
            for x in range(0, self.dimensions[0] - patch_size, step):
                # Check if patch contains enough tissue
                mask_x = int(x / scale_factor)
                mask_y = int(y / scale_factor)
                mask_patch_size = int(patch_size / scale_factor)
                
                mask_patch = tissue_mask[
                    mask_y:mask_y + mask_patch_size,
                    mask_x:mask_x + mask_patch_size
                ]
                
                tissue_ratio = np.sum(mask_patch > 0) / mask_patch.size
                
                if tissue_ratio > tissue_threshold:
                    # Extract patch at desired level
                    patch = self.slide.read_region(
                        (x, y), level, (patch_size, patch_size)
                    )
                    patch_rgb = np.array(patch.convert('RGB'))
                    patches.append(patch_rgb)
        
        return patches
    
    def color_normalization(self, image: np.ndarray, target_means: np.ndarray, target_stds: np.ndarray) -> np.ndarray:
        """Normalize staining colors using Reinhard method."""
        # Convert to LAB color space
        lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB).astype(np.float32)
        
        # Normalize each channel
        for i in range(3):
            channel = lab_image[:, :, i]
            channel_mean = np.mean(channel)
            channel_std = np.std(channel)
            
            # Normalize
            normalized_channel = (channel - channel_mean) / channel_std * target_stds[i] + target_means[i]
            lab_image[:, :, i] = np.clip(normalized_channel, 0, 255)
        
        # Convert back to RGB
        normalized_rgb = cv2.cvtColor(lab_image.astype(np.uint8), cv2.COLOR_LAB2RGB)
        return normalized_rgb
```

## Clinical Validation & Evaluation

### Medical AI Metrics
```python
from sklearn.metrics import (
    roc_auc_score, precision_recall_curve, confusion_matrix,
    cohen_kappa_score, matthews_corrcoef
)
from scipy.stats import pearsonr, spearmanr
import pandas as pd

class ClinicalEvaluator:
    """Comprehensive clinical evaluation metrics."""
    
    @staticmethod
    def compute_clinical_metrics(y_true: np.ndarray, y_pred: np.ndarray, y_scores: Optional[np.ndarray] = None) -> Dict[str, float]:
        """Compute comprehensive clinical evaluation metrics."""
        metrics = {}
        
        # Basic classification metrics
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
        
        metrics.update({
            'sensitivity': tp / (tp + fn),  # Recall
            'specificity': tn / (tn + fp),
            'ppv': tp / (tp + fp),  # Positive Predictive Value
            'npv': tn / (tn + fn),  # Negative Predictive Value
            'accuracy': (tp + tn) / (tp + tn + fp + fn),
            'f1_score': 2 * tp / (2 * tp + fp + fn),
            'mcc': matthews_corrcoef(y_true, y_pred),  # Matthews Correlation Coefficient
            'kappa': cohen_kappa_score(y_true, y_pred)  # Cohen's Kappa
        })
        
        # ROC AUC if probabilities available
        if y_scores is not None:
            metrics['auc'] = roc_auc_score(y_true, y_scores)
            
            # Precision-Recall curve
            precision, recall, _ = precision_recall_curve(y_true, y_scores)
            metrics['auprc'] = np.trapz(precision, recall)
        
        return metrics
    
    @staticmethod
    def bootstrap_confidence_intervals(
        y_true: np.ndarray, 
        y_pred: np.ndarray,
        metric_func: callable,
        n_bootstrap: int = 1000,
        confidence_level: float = 0.95
    ) -> Tuple[float, float, float]:
        """Compute bootstrap confidence intervals for metrics."""
        n_samples = len(y_true)
        bootstrap_scores = []
        
        for _ in range(n_bootstrap):
            # Bootstrap sampling
            indices = np.random.choice(n_samples, n_samples, replace=True)
            score = metric_func(y_true[indices], y_pred[indices])
            bootstrap_scores.append(score)
        
        # Compute confidence intervals
        alpha = 1 - confidence_level
        lower_percentile = (alpha / 2) * 100
        upper_percentile = (1 - alpha / 2) * 100
        
        ci_lower = np.percentile(bootstrap_scores, lower_percentile)
        ci_upper = np.percentile(bootstrap_scores, upper_percentile)
        mean_score = np.mean(bootstrap_scores)
        
        return mean_score, ci_lower, ci_upper

class BiasDetection:
    """Detect and quantify bias in medical AI models."""
    
    @staticmethod
    def demographic_parity_difference(
        y_true: np.ndarray, 
        y_pred: np.ndarray, 
        sensitive_attribute: np.ndarray
    ) -> float:
        """Compute demographic parity difference."""
        groups = np.unique(sensitive_attribute)
        positive_rates = []
        
        for group in groups:
            mask = sensitive_attribute == group
            positive_rate = np.mean(y_pred[mask])
            positive_rates.append(positive_rate)
        
        return max(positive_rates) - min(positive_rates)
    
    @staticmethod
    def equalized_odds_difference(
        y_true: np.ndarray, 
        y_pred: np.ndarray, 
        sensitive_attribute: np.ndarray
    ) -> Tuple[float, float]:
        """Compute equalized odds difference for TPR and FPR."""
        groups = np.unique(sensitive_attribute)
        tpr_diff = []
        fpr_diff = []
        
        for group in groups:
            mask = sensitive_attribute == group
            tn, fp, fn, tp = confusion_matrix(y_true[mask], y_pred[mask]).ravel()
            
            tpr = tp / (tp + fn) if (tp + fn) > 0 else 0
            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
            
            tpr_diff.append(tpr)
            fpr_diff.append(fpr)
        
        return max(tpr_diff) - min(tpr_diff), max(fpr_diff) - min(fpr_diff)
```

## Dependencies
```python
# Medical imaging core
monai[all]>=1.3.0
SimpleITK>=2.2.0
pydicom>=2.3.0
nibabel>=5.0.0
itk>=5.3.0

# Computer vision
opencv-python>=4.7.0
scikit-image>=0.20.0
albumentations>=1.3.0
imgaug>=0.4.0

# Digital pathology
openslide-python>=1.2.0
histomicstk>=1.3.0
cucim>=23.0.0  # NVIDIA RAPIDS cuCIM

# 3D visualization
vtk>=9.2.0
mayavi>=4.8.0
napari[all]>=0.4.18
itkwidgets>=0.32.0

# Clinical integration
dcm4che>=0.1.0
pynetdicom>=2.0.0

# GPU acceleration
cupy-cuda11x>=12.0.0  # or appropriate CUDA version
cucim>=23.0.0
```

## Best Practices

### Regulatory Compliance
- Implement proper validation protocols (FDA 510(k), CE marking)
- Maintain audit trails for model decisions
- Ensure data governance and patient privacy protection
- Document clinical validation studies and performance metrics
- Follow medical device software lifecycle processes (IEC 62304)

### Clinical Integration
- Design intuitive user interfaces for clinicians
- Provide uncertainty quantification and confidence intervals
- Implement proper fallback mechanisms for edge cases
- Ensure seamless integration with existing clinical workflows
- Maintain model interpretability and explainability

### Quality Assurance
- Implement continuous monitoring of model performance
- Detect dataset shift and model degradation
- Validate on diverse patient populations
- Monitor for algorithmic bias and fairness
- Maintain comprehensive testing across different imaging protocols

Remember: Medical AI requires rigorous validation, regulatory compliance, and close collaboration with clinical experts. Always prioritize patient safety and clinical utility over technical performance metrics.