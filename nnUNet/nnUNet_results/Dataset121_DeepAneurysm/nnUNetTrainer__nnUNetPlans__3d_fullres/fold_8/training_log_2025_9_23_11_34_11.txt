
This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 112, 'patch_size': [32, 64, 64], 'median_image_size_in_voxels': [32.0, 64.0, 64.0], 'spacing': [0.6999997496604919, 0.44920000433921814, 0.44920000433921814], 'normalization_schemes': ['NoNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'ResidualEncoderUNetClassifier', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'num_pool_per_axis': [3, 4, 4], 'pool_op_kernel_sizes': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset121_DeepAneurysm', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.6999989748001099, 0.44920000433921814, 0.44920000433921814], 'original_median_shape_after_transp': [85, 236, 286], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3.198979616165161, 'mean': 0.7366887643438168, 'median': 0.6796993017196655, 'min': -0.02173912525177002, 'percentile_00_5': 0.10982628911733627, 'percentile_99_5': 1.914076566696167, 'std': 0.36197441199421027}}} 
 
2025-09-23 11:34:21.717135: unpacking dataset... 
2025-09-23 11:34:22.884016: unpacking done... 
2025-09-23 11:34:22.885245: do_dummy_2d_data_aug: False 
2025-09-23 11:34:22.893412: Using splits from existing split file: /tmp/nnUNet_preprocessed/Dataset121_DeepAneurysm/splits_final.json 
2025-09-23 11:34:22.953412: The split file contains 100 splits. 
2025-09-23 11:34:22.953601: Desired fold for training: 8 
2025-09-23 11:34:22.953666: This split has 3594 training and 639 validation cases. 
2025-09-23 11:35:09.289097: Unable to plot network architecture: 
2025-09-23 11:35:09.289276: module 'torch.jit' has no attribute 'get_trace_graph' 
2025-09-23 11:35:09.661617:  
2025-09-23 11:35:09.661763: Epoch 0 
2025-09-23 11:35:09.661940: Current learning rate: 5e-05 
2025-09-23 12:41:42.098110: train_loss 0.5755 
2025-09-23 12:41:42.098489: train_seg_loss 0.2825 
2025-09-23 12:41:42.098697: train_cls_loss 0.293 
2025-09-23 12:41:42.098890: train_ce_loss 0.0129 
2025-09-23 12:41:42.099058: train_dice_loss 0.2696 
2025-09-23 12:41:42.099159: train_dice_loss0 0.2737 
2025-09-23 12:41:42.099241: train_dice_loss1 0.2768 
2025-09-23 12:41:42.099318: train_dice_loss2 0.2747 
2025-09-23 12:41:42.099393: train_dice_loss3 0.1979 
2025-09-23 12:41:42.099473: train_fake_dice_loss 0.2624 
2025-09-23 12:41:42.099550: val_loss 0.7359 
2025-09-23 12:41:42.099623: val_seg_loss 0.2212 
2025-09-23 12:41:42.099696: val_cls_loss 0.5147 
2025-09-23 12:41:42.099779: val_ce_loss 0.0077 
2025-09-23 12:41:42.099853: val_dice_loss 0.2135 
2025-09-23 12:41:42.099928: val_dice_loss0 0.218 
2025-09-23 12:41:42.100002: val_dice_loss1 0.2178 
2025-09-23 12:41:42.100076: val_dice_loss2 0.2132 
2025-09-23 12:41:42.100151: val_dice_loss3 0.1602 
2025-09-23 12:41:42.100224: val_fake_dice_loss 0.2108 
2025-09-23 12:41:42.100305: train Pseudo dice [0.6816] 
2025-09-23 12:41:42.100391: train deep_supervision dice0 0.7293 
2025-09-23 12:41:42.100468: train deep_supervision dice1 0.7309 
2025-09-23 12:41:42.105906: train deep_supervision dice2 0.7425 
2025-09-23 12:41:42.105990: train deep_supervision dice3 0.8205 
2025-09-23 12:41:42.106060: val Pseudo dice [0.637] 
2025-09-23 12:41:42.106131: val deep_supervision dice0 0.7829 
2025-09-23 12:41:42.106198: val deep_supervision dice1 0.7858 
2025-09-23 12:41:42.106263: val deep_supervision dice2 0.794 
2025-09-23 12:41:42.106328: val deep_supervision dice3 0.844 
2025-09-23 12:41:42.106392: train_accuracy 0.8762 
2025-09-23 12:41:42.106454: train_sensitivity 0.3074 
2025-09-23 12:41:42.106517: train_specificity 0.9682 
2025-09-23 12:41:42.106580: val_accuracy 0.8021 
2025-09-23 12:41:42.106645: val_sensitivity 0.0972 
2025-09-23 12:41:42.106713: val_specificity 0.983 
2025-09-23 12:41:42.106797: Epoch time: 3992.44 s 
2025-09-23 12:41:42.179852: Yayy! New best val EMA pseudo Dice: 0.637 
2025-09-23 12:41:45.080943:  
2025-09-23 12:41:45.081147: Epoch 1 
2025-09-23 12:41:45.081274: Current learning rate: 5e-05 
2025-09-23 13:47:09.036176: train_loss 0.5035 
2025-09-23 13:47:09.036440: train_seg_loss 0.265 
2025-09-23 13:47:09.036539: train_cls_loss 0.2386 
2025-09-23 13:47:09.036621: train_ce_loss 0.0116 
2025-09-23 13:47:09.036698: train_dice_loss 0.2533 
2025-09-23 13:47:09.036782: train_dice_loss0 0.2583 
2025-09-23 13:47:09.036857: train_dice_loss1 0.2585 
2025-09-23 13:47:09.036930: train_dice_loss2 0.2582 
2025-09-23 13:47:09.037003: train_dice_loss3 0.1832 
2025-09-23 13:47:09.037076: train_fake_dice_loss 0.2491 
2025-09-23 13:47:09.037148: val_loss 0.7761 
2025-09-23 13:47:09.037220: val_seg_loss 0.2195 
2025-09-23 13:47:09.037290: val_cls_loss 0.5567 
2025-09-23 13:47:09.037359: val_ce_loss 0.0093 
2025-09-23 13:47:09.037428: val_dice_loss 0.2102 
2025-09-23 13:47:09.037500: val_dice_loss0 0.2151 
2025-09-23 13:47:09.037573: val_dice_loss1 0.2148 
2025-09-23 13:47:09.037643: val_dice_loss2 0.2125 
2025-09-23 13:47:09.037721: val_dice_loss3 0.1473 
2025-09-23 13:47:09.037794: val_fake_dice_loss 0.2085 
2025-09-23 13:47:09.037867: train Pseudo dice [0.7032] 
2025-09-23 13:47:09.037942: train deep_supervision dice0 0.7437 
2025-09-23 13:47:09.038014: train deep_supervision dice1 0.7456 
2025-09-23 13:47:09.038085: train deep_supervision dice2 0.7527 
2025-09-23 13:47:09.038156: train deep_supervision dice3 0.826 
2025-09-23 13:47:09.038226: val Pseudo dice [0.6521] 
2025-09-23 13:47:09.038301: val deep_supervision dice0 0.7853 
2025-09-23 13:47:09.038373: val deep_supervision dice1 0.7868 
2025-09-23 13:47:09.038443: val deep_supervision dice2 0.7919 
2025-09-23 13:47:09.038513: val deep_supervision dice3 0.8583 
2025-09-23 13:47:09.038582: train_accuracy 0.9022 
2025-09-23 13:47:09.038650: train_sensitivity 0.4828 
2025-09-23 13:47:09.038725: train_specificity 0.9702 
2025-09-23 13:47:09.038795: val_accuracy 0.8014 
2025-09-23 13:47:09.038863: val_sensitivity 0.1454 
2025-09-23 13:47:09.038932: val_specificity 0.9748 
2025-09-23 13:47:09.039010: Epoch time: 3923.96 s 
2025-09-23 13:47:09.093721: Yayy! New best val EMA pseudo Dice: 0.6385 
2025-09-23 13:47:11.902744:  
2025-09-23 13:47:11.902950: Epoch 2 
2025-09-23 13:47:11.903074: Current learning rate: 5e-05 
